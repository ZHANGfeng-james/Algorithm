# 1 递归

递归 recursion 

一个实例：**推荐注册返佣金**的这个功能我想你应该不陌生吧？现在很多 App 都有这个功能。这个功能中，用户 A 推荐用户 B 来注册，用户 B 又推荐了用户 C 来注册。我们可以说，用户 C 的“最终推荐人”为用户 A，用户 B 的“最终推荐人”也为用户 A，而用户 A 没有**“最终推荐人”**。一般来说，我们会通过**数据库**来记录这种推荐关系。在数据库表中，我们可以记录两行数据，其中 actor_id 表示用户 id，referrer_id 表示推荐人 id。这就是一个非常典型的**递归实例**，每访问一个数据库 Record 都会触发一次查找推荐人的动作，直到 referrer_id 指定的推荐人不存在为止。

递归是一种**<u>应用非常广泛</u>**的**算法**（或者**编程技巧**），但却是**<u>最难理解的知识点</u>**。

再比如一个生活场景：周末你带着女朋友去电影院看电影，女朋友问你，**咱们现在坐在第几排啊？**电影院里面太黑了，看不清，没法数，现在你怎么办？于是你就问前面一排的人他是第几排，你想只要在他的数字上加一，就知道自己在哪一排了。但是，前面的人也看不清啊，所以他也问他前面的人。就这样一排一排往前问，直到问到第一排的人，说我在第一排，然后再这样一排一排再把数字传回来。直到你前面的人告诉你他在哪一排，于是你就知道答案了。

> 我去问了前面一排的人，**然而他也不知道**，紧接着他思考了一下（貌似他也是程序员）：**知道了，我去问问我的前面一排的人！**也就是将问题抛给有条件知道答案的人，或者说更加接近了能解决问题的答案。每一个 wise-man 在得到自己的答案后，会把自己的答案返回给抛出问题的上一人，如此这般，将答案最终返回给提出问题的人。

这就是**<u>一个非常标准的递归求解问题的分解过程</u>**，**去的过程叫“递”**，**回来的过程叫“归”**。基本上，所有的递归问题都可以用**递推公式**来表示。刚刚这个生活中的例子，我们用递推公式将它表示出来就是这样的：`f(n)=f(n-1)+1`，其中 `f(1)=1`。

`f(n)` 表示你想知道自己在哪一排，`f(n-1)` 表示前面一排所在的排数，`f(1)=1` 表示第一排的人知道自己在第一排。有了这个**递推公式**，我们就可以很轻松地将它改为递归代码，如下：

~~~go
func floor(n int) int {
    if n == 1 {
        return 1
    }
    return f(n - 1) + 1
}
~~~

刚刚这个例子是**<u>非常典型的递归</u>**，那究竟什么样的问题可以用递归来解决呢？我总结了三个条件，只要**同时满足以下三个条件**，就可以用递归来解决。

1. **一个问题的解可以分解为几个子问题的解**

   何为子问题？**子问题就是数据规模更小的问题**。比如，前面讲的电影院的例子，你要知道，“自己在哪一排”的问题，可以分解为“前一排的人在哪一排”这样一个子问题。

2. **这个问题与分解之后的子问题，除了数据规模不同，求解思路完全一样**

   比如电影院那个例子，你求解“自己在哪一排”的思路，和前面一排人求解“自己在哪一排”的思路，是一模一样的。

3. **存在递归终止条件**

   把问题分解为子问题，把子问题再分解为子子问题，一层一层分解下去，**<u>不能存在无限循环</u>**，这就需要有终止条件。

   还是电影院的例子，第一排的人不需要再继续询问任何人，就知道自己在哪一排，也就是 `f(1)=1`，这就是递归的终止条件。

写递归代码最关键的是**写出递推公式，找到终止条件**，剩下将递推公式转化为代码就很简单了。

一道简单的算法题目：假如这里有 n 个台阶，每次你可以跨 1 个台阶或者 2 个台阶，请问走这 n 个台阶有多少种走法？如果有 7 个台阶，你可以 2，2，2，1 这样子上去，也可以 1，2，1，1，2 这样子上去，总之走法有很多，那如何用编程求得总共有多少种走法呢？

实际上，可以**根据第一步的走法把所有走法分为两类**，第一类是**第一步走了 1 个台阶**，另一类是**第一步走了 2 个台阶**。所以 n 个台阶的走法就等于**<u>先走 1 阶后，n-1 个台阶的走法，再加上先走 2 阶后，n-2 个台阶的走法</u>**。用公式表示就是：`f(n) = f(n-1)+f(n-2)`。**有了递推公式，递归代码基本上就完成了一半**。递归终止条件就是 f(1)=1，f(2)=2。我们把递归终止条件和刚刚得到的递推公式放到一起就是这样的：

~~~go
f(1) = 1;
f(2) = 2;
f(n) = f(n-1)+f(n-2);
~~~

**写递归代码的关键就是找到如何将大问题分解为小问题的规律，并且基于此写出递推公式，然后再推敲终止条件，最后将递推公式和终止条件翻译成代码**。

> 此处的关键是：能将大问题分解为小问题，大问题和小问题指的是问题规模的改变，解题思路完全一致！

还有一种递归：**<u>一个问题要分解为多个子问题的情况</u>**，递归代码就没那么好理解了。我们可以这样做：如果一个问题 A 可以分解为若干子问题 B、C、D，你可以假设子问题 B、C、D 已经解决，在此基础上思考如何解决问题 A。而且，你只需要思考问题 A 与子问题 B、C、D 两层之间的关系即可，不需要一层一层往下思考子问题与子子问题，子子问题与子子子问题之间的关系。**屏蔽掉递归细节，这样子理解起来就简单多了**。

两种不同的思考方式：

1. 由下往上：假设子问题 B/C/D 都已经解决了，需要在此基础上解决问题 A；
2. 由上往下：问题 A 需要分解为子问题 B/C/D，紧接着问题 B 还能分解为其他的子问题，需要一层层往下分解。

因此，**编写递归代码的关键是，只要遇到递归，我们就把它抽象成一个递推公式，不用想一层层的调用关系，不要试图用人脑去分解递归的每个步骤**。

在解答递归问题时，要特别警惕如下情况：

* 递归代码要警惕堆栈溢出；
* 递归代码要警惕重复计算。为了避免重复计算，我们可以**通过一个数据结构（比如散列表）来保存已经求解过的 `f(k)`**。

递归有利有弊，**利是递归代码的表达力很强**，写起来非常简洁；而弊就是**空间复杂度高、有堆栈溢出的风险、存在重复计算、过多的函数调用会耗时较多等问题**。所以，**<u>在开发过程中，我们要根据实际情况来选择是否需要用递归的方式来实现</u>**。

# 2 排序

排序 sort 是最常见的算法。

最经典的、最常用的排序算法：**<u>冒泡排序、插入排序、选择排序、快速排序、归并排序、计数排序、基数排序、桶排序</u>**。

除了学习它的算法原理、代码实现之外，更重要的是要学会**如何评价、分析一个排序算法**。可以从下面 3 个方面入手：

* 执行效率

  最好情况、最坏情况、平均情况时间复杂度；时间复杂度的系数、常数 、低阶；比较次数和交换（或移动）次数。**有序度不同的数据，对于排序的执行时间肯定是有影响的，我们要知道排序算法在不同数据下的性能表现**。**在对同一阶时间复杂度的排序算法性能对比的时候，我们就要把系数、常数、低阶也考虑进来**。基于比较的排序算法的执行过程，会涉及两种操作，一种是**元素比较大小**，另一种是**元素交换或移动**。所以，如果我们在分析排序算法的执行效率的时候，应该把**比较次数和交换（或移动）次数**也考虑进去。

* 内存消耗

  算法的内存消耗可以通过空间复杂度来衡量，**<u>原地排序算法，就是特指空间复杂度是 `O(1)` 的排序算法</u>**。

* 稳定性

  还有一个重要的度量指标，**稳定性**。这个概念是说，**<u>如果待排序的序列中存在值相等的元素，经过排序之后，相等元素之间原有的先后顺序不变</u>**。如果相互之间的顺序没有改变，则是稳定的排序算法，反之，则是不稳定的排序算法。

## 2.1 冒泡

冒泡排序**只会操作相邻的两个数据**。每次冒泡操作都会对**相邻的两个元素**进行**比较**，看是否满足大小关系要求。如果不满足就让它俩互换。一次冒泡会让至少一个元素移动到它应该在的位置，重复 n 次，就完成了 n 个数据的排序工作。

~~~java
// 冒泡排序，a表示数组，n表示数组大小
public void bubbleSort(int[] a, int n) {
	if (n <= 1) return;
	for (int i = 0; i < n; ++i) {
	    // 提前退出冒泡循环的标志位
		boolean flag = false;
		for (int j = 0; j < n - i - 1; ++j) {
		  if (a[j] > a[j+1]) { // 交换
			int tmp = a[j];
			a[j] = a[j+1];
			a[j+1] = tmp;
			flag = true;  // 表示有数据交换      
		  }
		}
		if (!flag) break;  // 没有数据交换，提前退出
	}
}
~~~

冒泡排序是原地排序算法，是稳定排序算法。最好情况时间复杂度是 O(n)。而最坏的情况是，要排序的数据刚好是倒序排列的，我们需要进行 n 次冒泡操作，所以最坏情况时间复杂度为 O(n^2^)。

冒泡排序包含两个**操作原子**：比较和交换。**不管算法怎么改进，交换次数总是确定的，即为逆序度**。对于包含 n 个数据的数组进行冒泡排序，平均交换次数是多少呢？最坏情况下，初始状态的有序度是 0，所以要进行 `n * (n-1) / 2` 次交换。最好情况下，初始状态的有序度是 `n * (n-1) / 2`，就不需要进行交换。我们可以取个中间值 `n * (n-1) / 4`，来表示初始有序度既不是很高也不是很低的平均情况。平均情况下的时间复杂度就是 O(n^2^)。

## 2.2 插入

插入排序算法的思想：在一个**有序列**中插入一个元素时，需要先找到待插入的位置，并移动其他元素位置，执行插入操作。上述一系列操作能够**保持整个有序区的有序性**。

因此，插入排序算法的过程就是：我们将数组中的数据分为两个区间，**已排序区间**和**未排序区间**。初始已排序区间只有一个元素，就是数组的第一个元素。**插入算法的核心思想是取未排序区间中的元素，在已排序区间中找到合适的插入位置将其插入，并保证已排序区间数据一直有序**。重复这个过程，直到未排序区间中元素为空，算法结束。初始状态下，已排序区间最小，非排序区间最大。

插入排序也包含两种操作，一种是**元素的比较**，一种是**元素的移动**。当我们需要将一个数据 a 插入到已排序区间时，需要拿 a 与已排序区间的元素依次比较大小，找到合适的插入位置。找到插入点之后，我们还需要将插入点之后的元素顺序往后移动一位，这样才能腾出位置给元素 a 插入。

对于不同的查找插入点方法（从有序区的头到尾**、**从有序区的尾到头），元素的比较次数是有区别的。但对于一个给定的初始序列，**移动操作的次数总是固定的，就等于逆序度**。

~~~java
// 插入排序，a表示数组，n表示数组大小
public void insertionSort(int[] a, int n) {
	if (n <= 1) return;
	for (int i = 1; i < n; ++i) {
		int value = a[i];
		int j = i - 1;
		// 查找插入的位置，从有序区的尾部到头部进行查找
		for (; j >= 0; --j) {
			if (a[j] > value) {
				a[j+1] = a[j];  // 数据移动
			} else {
				break;
			}
		}
		a[j+1] = value; // 插入数据
	}
}
~~~

插入排序是原地排序、稳定的排序算法。如果我们**从尾到头**在有序数据组里面查找插入位置，每次只需要比较一个数据就能确定插入的位置。所以这种情况下，最好是**时间复杂度为 `O(n)`**。注意，这里是从尾到头遍历已经有序的数据。如果数组是倒序的，每次插入都相当于在数组的第一个位置插入新的数据，所以需要移动大量的数据，所以**最坏情况时间复杂度为 O(n^2^)**。我们**<u>在数组中插入一个数据的平均时间复杂度是多少吗？</u>**没错，是 O(n)。所以，对于插入排序来说，每次插入操作都相当于在数组中插入一个数据，循环执行 n 次插入操作，所以**平均时间复杂度为 O(n^2^)**。

## 2.3 选择

选择排序算法的实现思路有点类似插入排序，也分**已排序区间**和**未排序区间**。但是选择排序每次会从未排序区间中找到**最小的元素**，将其放到已排序区间的末尾。

对于一组未排序的数据，可分为未排序区和已排序区，前部分是已排序区，后部分是未排序区。选择排序算法的核心：从未排序区域中找出最小的元素，放入到已排序区，并能够保证有序区始终是有序的。

> 选择的含义，就是从未排序的区域中找到最小的元素值，并放入已排序区间的后一个元素！至此，排序区扩大一个元素访问，未排序区减少一个元素范围。

~~~java
public void selectionSort() {
	if (data == null || data.length == 1) {
		return;
	}

	int length = data.length;
	for (int m = 0; m < length - 1; ++m) {
		// 外层循环，已排序区逐渐扩大 [0 ~ m]
		int minIndex = m;
		// 遍历查找非排序区最小值
		for (int n = m + 1; n < length; ++n) {
			if (data[minIndex] > data[n]) {
				minIndex = n;
			}
		}

		// 值交换
		int value = data[m];
		data[m] = data[minIndex];
		data[minIndex] = value;
	}

	System.out.println("排序后：" + Arrays.toString(data));
}
~~~

选择排序空间复杂度为 O(1)，是一种原地排序算法。选择排序的最好情况时间复杂度、最坏情况和平均情况时间复杂度都为 O(n^2^)。选择排序是一种**<u>不稳定的</u>**排序算法。

对于上面 3 种排序算法：冒泡排序、插入排序和选择排序，有这样的疑问：冒泡排序和插入排序的时间复杂度都是 O(n^2^)，都是原地排序算法，为什么插入排序要比冒泡排序更受欢迎呢？

冒泡排序、插入排序和选择排序的**<u>运算特点</u>**：

1. 冒泡排序：对数据进行从小到大排列时，单次冒泡会将最大值交换到最末尾位置；
2. 插入排序：将整个数据分为已排序区和未排序区，取出未排序区的首个值插入到已排序区中；
3. 选择排序：将整个数据分为已排序区和未排序区，取出未排序区的最小值，和已排序区的末尾位置交换。

这 3 种排序算法时间复杂度都是 O(n^2^)，比较高，**适合小规模数据的排序**。

## 2.4 归并

归并排序和快速排序都用到了**分治思想**，非常巧妙。我们可以借鉴这个思想，来解决**<u>非排序的问题</u>**。

> 在计算机科学中，分治法是一种很重要的算法。字面上的解释是“分而治之”，就是**<u>把一个复杂的问题分成两个或更多的相同或相似的子问题，再把子问题分成更小的子问题……直到最后子问题可以简单的直接求解，原问题的解即子问题的解的合并</u>**。

如果要排序一个数组，我们先把数组**从中间分成前后两部分**，然后对前后两部分分别排序，再将排好序的两部分合并在一起，这样整个数组就都有序了。

归并排序算法的步骤可以拆分成：**分解、排序和合并**，这 3 个步骤。

* **分解**：逐步将问题进行拆分，将大问题分解成小问题；
* **排序、合并**：对最小粒度的问题进行排序，相当于是 2 个数字之间的排序问题，这就是最小粒度的问题；沿着分解的路径，进行合并（分解的逆过程）。逐步将小问题（已经解决排序问题）逐步扩展，还原为原先的内容。
* 归并排序算法的名称 `merge_sort`，其名称中暗含了算法的重点在于：**<u>排序和合并，其中合并就包含了排序的操作</u>**。

归并排序使用的就是**分治思想**。分治，顾名思义，就是**分而治之，将一个大问题分解成小的子问题来解决**。小的子问题解决了，大问题也就解决了。**分治算法一般都是用递归来实现的**。

**分治是一种解决问题的处理思想，递归是一种编程技巧，这两者并不冲突**。

~~~go
递推公式：
merge_sort(p…r) = merge(merge_sort(p…q), merge_sort(q+1…r))

终止条件：
p >= r 不用再继续分解
~~~

`merge_sort(p…r)` 表示，给下标从 `p` 到 `r` 之间的数组排序。我们将这个排序问题转化为了两个子问题，`merge_sort(p…q)` 和 `merge_sort(q+1…r)`，其中下标 `q` 等于 `p` 和 `r` 的中间位置，也就是 `(p+r)/2`。当下标从 `p` 到 `q` 和从 `q+1` 到 `r` 这两个子数组都**排好序**之后，我们再将两个有序的子数组**合并**在一起（**merge函数**的表达的含义），这样下标从 `p` 到 `r` 之间的数据就也排好序了。

转化成伪代码就是：

~~~c
// 归并排序算法, A是数组，n表示数组大小
merge_sort(A, n) {
  merge_sort_c(A, 0, n-1)
}

// 递归调用函数
merge_sort_c(A, p, r) {
  // 递归终止条件
  if p >= r  then return

  // 取p到r之间的中间位置q
  q = (p+r) / 2
  // 分治递归
  merge_sort_c(A, p, q)
  merge_sort_c(A, q+1, r)
  // 将A[p...q]和A[q+1...r]合并为A[p...r]
  merge(A[p...r], A[p...q], A[q+1...r])
}
~~~

实际上归并排序中涉及到的**递、归问题**，可以这样理解：

* 递：将大问题**拆解**成小问题；
* 归：指的就是 `merge()`，**在合并的同时做了排序操作**。

归并排序是一个**稳定的排序算法**。归并排序的执行效率与要排序的原始数组的有序程度无关，所以其时间复杂度是非常稳定的，不管是最好情况、最坏情况，还是平均情况，时间复杂度都是 `O(nlogn)`。归并排序的合并函数，在合并两个有序数组为一个有序数组时，需要**借助额外的存储空间**。临时内存空间最大也不会超过 n 个数据的大小，所以空间复杂度是 `O(n)`。

归并排序算法的实现：

~~~java
/**
 * 归并排序
 * 
 * @param p
 *            起始位置索引
 * @param r
 *            终止位置索引
 */
public void mergeSort(int firstIndex, int lastIndex) {
	// 递归终止条件
	if (firstIndex >= lastIndex) {
		return;
	}

	int middleIndex = (lastIndex + firstIndex) / 2;

	// 归并排序算法，使用递归思路实现
	// 将原先数组 A[0, n -1] 拆分为两个子数组以及两个子问题： A[0, (n-1)/2] 和 A[(n-1)/2 + 1, n-1]
	mergeSort(firstIndex, middleIndex);
	mergeSort(middleIndex + 1, lastIndex);

	// 分别对上述子数组进行递归排序
	// 递归到最小粒度，实际是两个值的合并问题，排好序的两个子数组进行合并
	// 将两个子问题数组合并：两个子问题： A[0, (n-1)/2] 和 A[(n-1)/2 + 1, n-1]
	mergeArray(data, firstIndex, middleIndex + 1, lastIndex);
}

/**
 * 合并两个子数组
 * 
 * @param arr1
 *            子数组
 * @param p
 *            数组中的起始位置索引
 * @param q
 *            数组中的终止位置索引
 * @param r
 *            终止位置索引
 */
public void mergeArray(int[] arr1, int p, int q, int r) {
	// System.out.println("mergeArray " + "p:" + p + "; q:" + q + "; r:" + r);

	// 子数组1遍历的起始位置索引，q-1 相当于是数组1的终止位置索引
	int i = p;
	// 子数组2遍历的起始坐标，r 相当于是数组2的终止位置索引
	int j = q;

	int k = 0;

	// 申请临时数组
	int[] tmp = new int[r - p + 1];
	// System.out.println("tmp.length:" + tmp.length);

	while (i <= q - 1 && j <= r) {
		if (data[i] > data[j]) {
			tmp[k++] = data[j++];
		} else {
			tmp[k++] = data[i++];
		}
	}

	// 默认：子数组 1 还没有遍历完
	int start = i;
	int end = q - 1;

	// j = 2, i = 0

	if (j <= r) {
		// 子数组 2 还没有遍历完
		start = j;
		end = r;
	} else if (i <= q) {
		// do nothing
	}

	// 将还没有遍历完的子数组内容拷贝到 tmp 数组
	while (start <= end) {
		tmp[k++] = data[start++];
	}

	// 将 tmp 数组内容还原到 data 数组
	for (int index = 0; index < tmp.length; ++index) {
		data[p + index] = tmp[index];
	}
}
~~~

## 2.5 快排

快排的思想（也是分治的思想）是这样的：如果要排序数组中下标从 p 到 r 之间的一组数据，我们选择 p 到 r 之间的**任意一个数据作为 `pivot`（分区点）**。

我们遍历 p 到 r 之间的数据，将小于 `pivot` 的放到左边，将大于 `pivot` 的放到右边，将 `pivot` 放到中间。经过这一步骤之后，数组 p 到 r 之间的数据就被分成了三个部分，前面 p 到 q-1 之间都是小于 `pivot` 的，中间是 `pivot`，后面的 q+1 到 r 之间是大于 `pivot` 的。

根据分治、递归的处理思想，我们可以**<u>用递归排序下标从 p 到 q-1 之间的数据和下标从 q+1 到 r 之间的数据</u>**，直到区间缩小为 1，就说明所有的数据都有序了。

如果我们用递推公式来将上面的过程写出来的话，就是这样：

~~~
递推公式：quick_sort(p…r) = quick_sort(p…q-1) + quick_sort(q+1… r)
终止条件：p >= r
~~~

跟归并排序一样，用伪代码来实现：

~~~
// 快速排序，A是数组，n表示数组的大小
quick_sort(A, n) {
  quick_sort_c(A, 0, n-1)
}
// 快速排序递归函数，p,r为下标
quick_sort_c(A, p, r) {
  if p >= r then return
  
  q = partition(A, p, r) // 获取分区点，并间 [p, r]的区间划分为 3 个部分：小于 A[pivot]；等于 A[pivot]；大于 A[pivot] 的 3 个部分
  quick_sort_c(A, p, q-1)
  quick_sort_c(A, q+1, r)
}
~~~

`partition()` 分区函数就是**随机选择一个元素**作为 `pivot`（**一般情况下**，可以选择 p 到 r 区间的**最后一个元素**），然后对 `A[p…r]` 分区，函数返回 `pivot` 的下标。`partition()` 分区的功能：默认选择最后一个元素作为分区点值，将数组拆分成 3 个部分，也就是：小于分区点值，大于分区点值以及等于分区点的值。在实现 `partition()` 时，可利用插入排序中的移动元素操作，实现原地排序（多个指针操作，比较和交换）。

归并排序和快速排序都是使用了分而治之的思想，但是处理过程有不同：

* 归并排序的处理过程是**由下到上**的，先处理子问题，然后再合并。
* 快排正好相反，它的处理过程是**由上到下**的，先分区，然后再处理子问题。

归并之所以是**非原地排序**算法，主要原因是**合并函数无法在原地执行**。快速排序通过设计巧妙的**原地分区函数**，可以实现原地排序，解决了归并排序占用太多内存的问题。

快速排序有一个可以利用的地方：每一次排序都得到了一个大于 pivot 和小于 pivot 的序列，因此我们在查找最大值或最小值时，可以利用这些序列。比如：`O(n)` 时间复杂度内求无序数组中的第 `K` 大元素。比如，`4，2，5，12，3` 这样一组数据，第 3 大元素就是 4。

我们选择数组区间 A[0…n-1] 的最后一个元素 A[n-1] 作为 `pivot`，对数组 A[0…n-1] **<u>原地分区</u>**，这样数组就分成了三部分，A[0…p-1]、A[p]、A[p+1…n-1]。将数组中所有的元素简单拆分成了和 `A[p]` 相关的 3 个部分：

* 如果 `p + 1 = K`，那 A[p] 就是要求解的元素；
* 如果 `K > p + 1`, 说明第 K 大元素出现在 A[p+1…n-1] 区间，我们再按照上面的思路递归地在 A[p+1…n-1] 这个区间内查找；
* 同理，如果 `K < p + 1`，那我们就在 A[0…p-1] 区间查找。

因此，我们在处理这个问题时，实际上是忽略了另一半数据的查找过程，这本身就体现了效率的提升。在**时间复杂度有限制**的情况下（比如 `O(nlogn)`），找到第 `K` 大的值。即然时间复杂度有限制，**当然不能对数据进行全排列**，再进行遍历，这显示不是符合题目要求的解答办法。分治思想的应用，以某个值作为分界，遍历一次全数据，将整个数据内容划分为 3 个部分。那下次遍历时就不需要再进行全遍历了，只需要在指定范围内遍历。

## 2.6 桶

**桶排序**、**计数排序**、**基数排序**，这些排序算法的**时间复杂度是线性的**，所以把这类排序算法叫作**线性排序**（Linear sort）。之所以能做到线性的时间复杂度，主要原因是，这三个算法是**非基于比较的排序算法**，都不涉及元素之间的比较操作。但是这些排序算法是有使用前提的：对要排序的数据要求很苛刻。而这些算法的**适用场景**就是我们需要掌握的重点。

桶排序（Bucket sort）。桶排序，顾名思义，会用到“桶”，核心思想是**将要排序的数据分到几个有序的桶里，每个桶里的数据再单独进行排序**。桶内排完序之后，再把每个桶里的数据按照顺序依次取出，组成的序列就是有序的了。

如果要排序的数据有 n 个，我们把它们均匀地划分到 m 个桶内，每个桶里就有 k=n/m 个元素。每个桶内部使用**快速排序**，时间复杂度为 `O(k * logk)`。m 个桶排序的时间复杂度就是 `O(m * k * logk)`，因为 k=n/m，所以整个桶排序的时间复杂度就是 O(n*log(n/m))。当桶的个数 m 接近数据个数 n 时，log(n/m) 就是一个非常小的常量，这个时候桶排序的时间复杂度接近 O(n)。

桶排序算法的适用场景：

* 要排序的数据需要**很容易就能划分成 m 个桶**，并且，**桶与桶之间有着天然的大小顺序**。这样**每个桶内的数据都排序完之后，桶与桶之间的数据不需要再进行排序**。
* 数据在各个桶之间的**分布是比较均匀**的。在极端情况下，如果数据都被划分到一个桶里，那就退化为 `O(nlogn)` 的排序算法了。

**桶排序比较适合用在外部排序中**。所谓的外部排序就是**数据存储在外部磁盘**中，数据量比较大，内存有限，无法将数据全部加载到内存中。

比如说我们有 `10GB` 的订单数据，我们希望**按订单金额（假设金额都是正整数）进行排序**，但是我们的内存有限，只有几百 MB，没办法一次性把 `10GB` 的数据都加载到内存中（**也就是说不能将数据一次性读取到内存中做全排列**）。这个时候该怎么办呢？

解决办法是这样的：一次数据遍历，找到 `10GB` 数据的数值范围，由此计算出桶的个数；再次进行遍历，依次读取数据并写入到这些桶对应的文件中；依次对这些文件中的数据进行快排，快排让各个文件中的数据有序；将子文件组装成最终的有序文件。**针对这些划分之后还是比较大的文件，我们可以继续划分**，比如，订单金额在 1 元到 1000 元之间的比较多，我们就将这个区间继续划分为 10 个小区间，1 元到 100 元，101 元到 200 元，201 元到 300 元…901 元到 1000 元。如果划分之后，101 元到 200 元之间的订单还是太多，无法一次性读入内存，那就继续再划分，直到所有的文件都能读入内存为止。

## 2.7 计数

**计数排序（`Couting` sort）其实是桶排序的一种特殊情况**。当要排序的 n 个数据，所处的范围并不大的时候，比如最大值是 k，我们就可以把数据划分成 k 个桶。**每个桶内的数据值都是相同的**，省掉了桶内排序的时间（每个桶，对应的就是一个值）。

比如考生的分数：考生的满分是 900 分，最小是 0 分，这个数据的范围很小，所以我们可以**分成 901 个桶，对应分数从 0 分到 900 分**。根据考生的成绩，我们将这 50 万考生划分到这 901 个桶里。**桶内的数据都是分数相同的考生**，所以并不需要再进行排序。我们只需要依次扫描每个桶，将桶内的考生依次输出到一个数组中，就实现了 50 万考生的排序。因为只涉及**扫描遍历**操作，所以时间复杂度是 O(n)。

计数排序的算法思想就是这么简单，跟桶排序非常类似，**只是桶的大小粒度不一样**。

**为什么叫“计数”排序？计数的含义是什么？**因为排序过程中利用了另外一个**数组**来**计数**实现的。

计数排序**只能用在数据范围不大的场景中**，如果数据范围 k 比要排序的数据 n 大很多，就不适合用计数排序了。而且，计数排序只能给非负整数排序，如果要排序的数据是其他类型的，要将其在不改变相对大小的情况下，转化为非负整数。

## 2.8 基数

基数排序的思想是由这个例子引申出来的：假设我们有 10 万个手机号码，希望将这 10 万个手机号码从小到大排序，你有什么比较快速的排序方法呢？

基数排序对要排序的数据是有要求的，需要可以**分割出独立的“位”来比较**，而且**位之间有递进的关系**，如果 a 数据的高位比 b 数据大，那剩下的低位就不用比较了。除此之外，每一位的数据范围不能太大，要可以用线性排序算法来排序，否则，基数排序的时间复杂度就无法做到 O(n) 了。

刚刚这个问题里有这样的规律：假设要比较两个手机号码 a，b 的大小，**如果在前面几位中，a 手机号码已经比 b 手机号码大了，那后面的几位就不用看了**。

先来看看这样的例子：我们现在要给电商交易系统中的“订单”排序。订单有两个属性，一个是下单时间，另一个是订单金额。如果我们现在有 10 万条订单数据，我们希望按照**<u>金额</u>**从小到大对订单数据排序。对于金额相同的订单，我们希望按照**<u>下单时间</u>**从早到晚有序。对于这样一个排序需求，我们怎么来做呢？我们详细分析这个排序需求：金额从小到大排序，金额相同时，按下单时间从早到晚排序。

对于程序设计来说，这个排序实体可被封装成一个实体，其中包含 2 个字段：订单金额和下单时间。那排序算法会对上述 2 个属性进行比较和交换。

最先想到的思路是这样的：先按照订单金额排序，紧接着在排完序的结果中对相同金额的订单按照时间排序。但是，**你思考下该如何实现？计算机实现起来是否有难度？**

一个**更容易实现的方式**是，借助稳定排序的思路：我们先**按照下单时间给订单排序**，注意是按照下单时间，不是金额。排序完成之后，我们用稳定排序算法，**按照订单金额**重新排序。两遍排序之后，我们得到的订单数据就是按照金额从小到大排序，金额相同的订单按照下单时间从早到晚排序的。为什么呢？

重点来看看，经过第一轮排序后的结果是这样的：订单是按照时间先后顺序排序的。特别是相同金额的订单，是按照时间先后顺序排序的。紧接着，再按照金额进行排序，此时排序的比较属性是订单金额。根据稳定排序的特性，相同金额的订单前后关系不会发生改变，因此这些订单的时间先后顺序就不会再改变。因此达到了目的和要求。

借助相同的处理思路，**先按照最后一位来排序手机号码**，然后，**再按照倒数第二位重新排序**，以此类推，最后按照第一位重新排序。经过 11 次排序之后，手机号码就都有序了。

## 2.9 排序算法总结

桶排序和计数排序的排序思想是非常相似的，都是针对范围不大的数据，将数据划分成不同的桶来实现排序。基数排序要求数据可以划分成高低位，位之间有递进关系。比较两个数，我们只需要比较高位，高位相同的再比较低位。而且每一位的数据范围不能太大，因为基数排序算法需要借助桶排序或者计数排序来完成每一个位的排序工作。

各个排序算法的时间复杂度总结如下：

| 类型 |     排序算法     | 时间复杂度 | 是否基于比较 |
| :--: | :--------------: | :--------: | :----------: |
|  1   | 冒泡、插入、选择 |  O(n^2^)   |      是      |
|  2   |    快排、归并    |  O(nlogn)  |      是      |
|  3   |  桶、计数、基数  |    O(n)    |      否      |

**为什么**归并排序、快速排序要比冒泡、插入和选择排序的时间复杂度要高？是什么原因？

归并排序和快速排序，使用的都是分而治之的思想，也就是每次排序都只对一半的数据进行处理。特别是快速排序，每次都使用 pivot 将待排序数据划分为 3 个区域。

# 3 二分查找

二分查找（Binary Search）算法，也叫**折半查找算法**。

**二分查找针对的是一个有序的数据集合，查找思想有点类似分治思想**。每次都通过跟区间的中间元素对比，将待查找的区间缩小为之前的一半，直到找到要查找的元素，或者区间被缩小为 0。

二分查找的时间复杂度就是 `O(logn)`。这是一种极其高效的时间复杂度，有的时候甚至比时间复杂度是常量级 O(1) 的算法还要高效。

二分查找中，最简单的情况就是**有序数组**中**不存在重复元素**。

~~~java
public int bsearch(int[] a, int n, int value) {
  int low = 0;
  int high = n - 1;

  while (low <= high) {
    int mid = (low + high) / 2;
    if (a[mid] == value) {
      return mid;
    } else if (a[mid] < value) {
      low = mid + 1;
    } else {
      high = mid - 1;
    }
  }

  return -1;
}
~~~

对应的递归实现是这样的：

~~~java
public int bsearch(int[] a, int n, int val) {
  return bsearchInternally(a, 0, n - 1, val);
}

private int bsearchInternally(int[] a, int low, int high, int value) {
  if (low > high) return -1;

  int mid =  low + ((high - low) >> 1);
  if (a[mid] == value) {
    return mid;
  } else if (a[mid] < value) {
    return bsearchInternally(a, mid+1, high, value);
  } else {
    return bsearchInternally(a, low, mid-1, value);
  }
}
~~~

二分查找应用场景的局限性：

* 二分查找依赖的是顺序表结构，简单点说就是数组；
* 二分查找针对的是有序数据；
* 数据量太小不适合二分查找；
* 数据量太大也不适合二分查找。二分查找的底层需要依赖**数组**这种数据结构，而数组为了支持随机访问的特性，**要求内存空间连续，对内存的要求比较苛刻**。

二分查找的核心思想理解起来非常简单，有点类似**分治思想**。即每次都通过跟区间中的中间元素对比，将待查找的区间缩小为一半，直到找到要查找的元素，或者区间被缩小为 0。二分查找更适合处理静态数据，也就是没有频繁的数据插入、删除操作。

二分查找的变形问题：

* 查找第一个值等于给定值的元素
* 查找最后一个值等于给定值的元素
* 查找第一个大于等于给定值的元素
* 查找最后一个小于等于给定值的元素

**很多人都觉得变形的二分查找很难写，主要原因是太追求第一种那样完美、简洁的写法**。而对于我们做工程开发的人来说，**代码易读懂、没 Bug，其实更重要**。因此，我们需要做的是：能写出符合需求的代码，需要不断细化情况，在不断细化中针对各种场景做处理；对于工程开发的人来说，代码易读懂，没有 `Bug`。

# 4 迭代

迭代和递归的区别是什么？





# 5 搜索



# 6 哈希算法



# 7 贪心算法



# 8 分治算法



# 9 回溯算法



# 10 动态规划



# 11 字符串匹配算法

