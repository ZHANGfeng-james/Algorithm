> 数据结构和算法有什么关系呢？**为什么大部分书都把这两个东西放到一块儿来讲呢**？这是因为，**数据结构和算法是相辅相成的**。**数据结构是为算法服务的，算法要作用在特定的数据结构之上**。因此，我们无法孤立数据结构来讲算法，也无法孤立算法来讲数据结构。
>
> 比如，因为数组具有**随机访问**的特点，常用的二分查找算法需要用数组来存储数据。但如果我们选择**链表**这种数据结构，二分查找算法就无法工作了，因为链表并不支持随机访问。

**什么是数据结构**？数据结构就是一组数据的存储结构。而算法则是操作数据的一组方法。数据结构是**静态的**，它只是**组织数据的一种方式**。如果不在它的基础上操作、构建算法，孤立存在的数据结构就是没用的。**我们在总结线性表时，要特别注意数据结构的特点、使用场景和（与其他数据结构的使用）区别。**

线性表和非线性表的概念：

* 线性表就是**数据排成像一条线一样的结构**。**每个线性表上的数据最多只有前和后两个方向**。**其实除了数组，链表、队列、栈等也是线性表结构**。
* 非线性表，比如**二叉树、堆、图**等。之所以叫非线性，是因为，**在非线性表中，数据之间并不是简单的前后关系**。

线性表数据结构有：**数组、链表、栈和队列**。更深入来看：此处的线性表结构可笼统认为是一种**逻辑**关系，是**一种元素间的逻辑关系**，类似于“手拉手”的关系。但站在**存储结构**的观点上来看，数组和链表则是一种完全不同的数据结构，前者存储在内存的相邻单元，而后者则是零散分布在内存中。另外，对于栈和队列的区分，其区别点则在**数据结构中元素的操作**上，插入、删除操作的限制让数组、链表扩展出了新的数据结构。



<img src="./img/Snipaste_2018-11-03_09-41-29.png" style="zoom:50%;" />

因此，总的来说，线性表结构需要考虑的是：**数据逻辑结构**、**存储结构**和**数据的操作**。这样思考：

1. 数据结构的**逻辑结构**：数据结构中各个元素之间的逻辑关系。比如对于线性表就是数据排成**像一条线一样的结构**。每个线性表上的数据最多只有**前和后两个方向**；而非线性表，数据之间并**不是简单的前后关系**。从数据结构的逻辑结构层面来看，可以**分为线性表和非线性表这 2 种**。
2. 数据结构的**存储结构**：数据结构在实现上，各个内存之间的关系。比如**数组**是使用连续的内存空间存储各元素内容，**链表**则是使用非连续内存存放元素内容。
3. 数据结构中**数据的操作**：栈和队列的区别就在此，认为规定了栈顶（栈底）和队列首部（队列尾部）。对于栈来说，只能在栈顶操作，是 FILO 型的；对于队列来说，只能在队列首部出队，在队列尾部入队，是 FIFO 型的。

# 1 数组

数组( `Array` )是一种线性表数据结构。它用一组**连续的内存空间**，来存储一组具有**相同类型的数据**。从概念上来说，这种数据结构有如下特性：

* 线性表结构：元素之间的关系类似于“手拉手”；
* 连续的内存空间，存储相同类型的数据（每个元素占用内存空间相同）：**具备了一个堪称"杀手锏"的特性——“随机访问”**，随机访问的时间复杂度是 O(1)。

**重点掌握**的是：这种基本数据结构——数组——的增加（insert）、删除、查找**基础操作**的**执行过程**。

> ”链表适合插入、删除，时间复杂度 `O(1)`；数组适合查找，查找时间复杂度为 `O(1)`"。这种说法实际是错误的！
>
> 数组是适合查找操作，但是**查找的时间复杂度并不为 `O(1)`**。即便是排好序的数组，你用二分查找，时间复杂度也是 `O(logn)`。所以，正确的表述应该是**，数组支持随机访问，根据下标随机访问的时间复杂度为 `O(1)`**。
>
> 查找是一种**算法**，是一种基于具体数据结构上的算法，比如二分搜索/查找。

先来看看**插入操作**，数组这种数据结构的**内存连续性**严重影响了插入操作的效率。假设数组的长度为 `n`，现在，如果我们需要将一个数据插入到数组中的第 `k` 个位置。为了把第 `k` 个位置腾出来（**保持存储的连续性**），给新来的数据，我们需要将第 `k ~ n` 这部分的元素都顺序地往后挪一位。如果在数组的末尾插入元素，那就不需要移动数据了，这时的时间复杂度为 `O(1)`。但如果在数组的开头插入元素，那所有的数据都需要依次往后移动一位，所以最坏时间复杂度是 `O(n)` 。因为我们在每个位置插入元素的概率是一样的，所以平均情况时间复杂度为 `( 1 + 2 + ... + n) / (n + 1) = O(n)`。

如果数组的**数据是有序的**，插入数据时，就必须按照上述过程移动元素，保持存储元素内存的连续性。**如果数组中存储的数据并没有任何规律**，数组只是被当作一个存储数据的集合（容器）。在这种情况下，如果要将某个数组插入到第 `k` 个位置，为了避免大规模的数据搬移，我们还有一个简单的办法就是，直接将第 `k` 位的数据搬移到数组元素的最后，把新的元素直接放入第 `k` 个位置（相当于是做一次交换）。

再来看看**删除操作**，跟插入数据类似，如果我们要**删除第 k 个位置的数据**，为了内存的连续性，也需要搬移数据，不然中间就会出现空洞，内存就不连续了。和插入类似，如果删除数组末尾的数据，则最好情况时间复杂度为 `O(1)`；如果删除开头的数据，则最坏情况时间复杂度为 `O(n)`；平均情况时间复杂度也为 `O(n)`。实际上，在某些特殊场景下，我们并不一定非得追求数组中数据的连续性。如果我们将多次删除操作集中在一起执行，删除的效率就会提高很多！每次的删除操作并不是真正地搬移数据，只是记录数据已经被删除（元素的 isDelete 标记）。**当数组没有更多空间存储数据时**，我们**再触发**执行一次真正的删除操作，这样就大大减少了删除操作导致的数据搬移。这就是 JVM 的**标记清除垃圾回收算法**的核心思想！

下面，我们以 Java 语言内部实现的容器类 ArrayList 为原型，来分析数组的操作：

~~~java
/**
 * 向 Array 中增加 value 元素，默认向 Array 尾部增加
 * 
 * @param value
 *            待加入的元素值
 * @return true 增加成功，反之，失败
 */
public boolean add(int value) {
	return insert(size, value);
}

/**
 * 向 Array 的指定 index 位置索引插入数值，待插入位置索引不能超出 size（Array 中已存入的元素个数，或者表示下一个添加元素的位置索引）
 * 
 * @param index
 *            待插入位置索引
 * @param value
 *            待插入数值
 * @return true 插入成功，反之，失败
 */
public boolean insert(int index, int value) {
	if (size == capacity) {
		// 若插入成功，需提前判断 Array 容量是否够用
		System.out.println("已无可用空间");
		return false;
	}

	// 允许在 size != capacity 的情况下，在数组末尾增加元素，此时 index 值为 size
	if (index < 0 || index > size) {
		System.out.println("待插入位置索引，不正确");
		return false;
	}
	
	// 允许在 index 值为 size 的地方插入数据，相当于是数组末尾插入
	
	// TODO 方式一：从 Array 尾部依次将元素向后挪动
	/*for (int m = size - 1; m >= index; --m) {
		array[m + 1] = array[m];
	}*/

	// TODO 方式二：从 Array 尾部依次将元素向后挪动，更加直观，代码可读性更强
	for (int m = size; m > index; --m) {
		array[m] = array[m - 1];
	}

	// 在指定位置插入数据
	array[index] = value;

	// 对于此处需要更新 size 的情况，可采用 ++size，因为该语句的目的就是让 size 自增
	++size;

	return true;
}

public int remove(int index) {
    if (index >= size){
        System.out.println("待移除的 index 超出可用范围，其中包含了：array 为空的情况");
    }
    int oldValue = array[index];
    
    int numMoved = size - index - 1;
    for (int i = 0; i < numMoved; i++){
        array[index + i] = array[index + i + 1]
    }
    --size;
    return oldValue;
}
~~~

**数组用一块连续的内存空间，来存储相同类型的一组数据**，最大的特点就是支持随机访问，但插入、删除操作也因此变得比较低效，平均情况时间复杂度为`O(n)`。在平时的业务开发中，我们可以直接使用编程语言提供的容器类，但是，如果是特别底层的开发，直接使用数组可能会更合适。

# 2 链表

链表是一种经常和数组比较的数据结构，但区别在于：数据存储结构是**分散的**，而不是像数组那样连续的内存占用（**内存的组织方式**）。

**数组**需要一块**连续的内存空间**来存储，**对内存的要求比较高**。如果我们申请一个 `100MB` 大小的数组，当内存中没有连续的、足够大的存储空间时，即便内存的剩余总可用空间大于 `100MB`，仍然会申请失败。而**链表**恰恰相反，它并**不需要一块连续的内存空间**，它**通过“指针”**将一组**零散的内存块串联**起来使用，所以如果我们申请的是 `100MB` 大小的链表，根本不会有问题。

三种最常见的链表结构，分别是：**单链表**、**双向链表**和**循环链表**。这些多种多样的链表实际都是对单链表的应用，在其基础上做的改进和创新！

**链表通过指针将一组零散的内存块串联在一起**。其中，我们把内存块称为**链表的“结点”**。为了将所有的结点串起来，每个链表的结点除了存储数据之外，还需要记录链上的下一个节点的地址。如图所示，我们把这个记录下个结点地址的指针叫作**后继指针`next`**。

![](./img/Snipaste_2021-09-02_17-28-21.png)

在上图的**单链表**中，你应该可以发现，其中有两个结点是比较特殊的，它们分别是**<u>第一个结点</u>**和**<u>最后一个结点</u>**。我们习惯性地把第一个结点叫作**头结点**，把最后一个结点叫作**尾结点**。其中，<u>头结点用来记录链表的**基地址**。有了它，我们就可以遍历到整条链表（找到头结点，就可以依次遍历所有单链表）</u>。而尾结点特殊的地方是：指针不是指向下一个结点，而是指向一个**空地址 `NULL`**，表示这是链表上最后一个结点。

> 上图中的头结点，就是第一个结点。

**重点掌握**的是：这种基本数据结构——链表——的增加（insert）、删除、查找**基础操作**的**执行过程**。

在链表中插入或者删除一个数据，我们并不需要为了保持内存的连续性而搬移结点，因为链表的存储空间本身就不是连续的。所以，**在链表中插入和删除一个数据是非常快速的**。针对链表的插入和删除操作，我们只需要考虑相邻结点的指针改变，所以对应的时间复杂度是 `O(1)`。

链表要想随机访问第 `k` 个元素，就没有数组那么高效了。因为链表中的数据并非连续存储的，所以无法像数组那样，根据首地址和下标，通过寻址公式就能直接计算出对应的内存地址，而是需要**根据指针一个结点一个结点地依次遍历，直到找到相应的结点**。，链表**随机访问**的性能没有数组好，需要 `O(n)` 的时间复杂度（**链表的插入和删除操作，时间花销在结点查找上**，而实际的删除和增加操作并不花费时间）。

接下来是单链表的复杂升级版本：循环链表和双向链表。

**循环链表是一种特殊的单链表**。实际上，循环链表也很简单。它跟单链表唯一的区别就在尾结点。我们知道，单链表的尾结点指针指向空地址，表示这就是最后的结点了。而循环链表的**尾结点指针**是指向链表的**头结点**。从我画的循环链表图中，你应该可以看出来，它**像一个环一样首尾相连**，所以叫做“循环”链表。和单链表相比，循环链表的优点是从链尾到链头比较方便。<u>当要处理的数据具有环型结构特点时，就特别适合采用循环链表</u>。

在实际的软件开发中，更加**常用的链表**结构：**双向链表**。单向链表只有一个方向，结点只有一个**<u>后继指针</u>** `next` 指向后面的结点。而双向链表，顾名思义，它支持两个方向，每个结点不止有一个后继指针 `next` 指向后面的结点，还有一个**<u>前驱指针</u>** `prev` 指向前面的结点。

![](./img/Snipaste_2021-09-02_17-42-47.png)

双向链表需要额外的两个空间来存储**后继结点**和**前驱结点**的地址。所以，如果存储同样多的数据，双向链表要比单链表占用更多的内存空间。虽然两个指针比较浪费存储空间，但可以支持双向遍历，这样也带来了双向链表操作的灵活性。从结构上来看，双向链表可以支持 `O(1)` 时间复杂度的情况下找到前驱结点，正是这样的特点，也使双向链表在某些情况下的插入、删除等操作都要比单链表简单、高效。除了插入、删除操作有优势之外，对于一个**有序链表**，双向链表的按值查询的效率也要比单链表高一些。因为，我们可以记录上次查找的位置 `p`，每次查询时，根据要查找的值与 `p` 的大小关系，决定是往前还是往后查找，所以**平均只需要查找一半的数据**。

> 此处有一个**设计思想**——**用空间换时间**：当内存空间充足的时候，如果我们更加追求代码的执行速度，我们就可以选择空间复杂度相对较高、但时间复杂度相对很低的算法或者数据结构。相反，如果内存比较紧缺，比如代码跑在手机或者单片机上，这个时候，就要反过来用时间换空间的设计思路。
>
> **缓存实际上就是利用了空间换时间的设计思想**。如果我们把数据存储在硬盘上，会比较节省内存，但每次查找数据都要询问一次硬盘，会比较慢。但如果我们通过**缓存技术**，事先**将数据加载在内存中**，虽然会比较耗费内存空间，但是每次数据查询的速度就大大提高了。实际上这种“空间换时间”的思路，就是为了**<u>适配不同读取速度的设备</u>**，比如：磁盘和内存的不同读取速度。

把循环链表和双向链表结合起来，就是双向循环链表！

![](./img/Snipaste_2021-09-02_17-49-15.png)

比较而言，自然会思考一个问题：既然有了数组，为什么还需要链表？

* 数组和链表，针对其基本的增加、删除、查找操作对应的时间复杂度是不同的；
* 数组的内存组织方式连续的，而且容器的大小是固定的。如果需要扩容，则需要拷贝原来的数据到新容器中。链表的内存组织方式是零散的，分布在内存区域的各个地方，而且**天然地支持动态扩容**。这一点是两者的最大不同。

# 3 队列















# 4 栈



