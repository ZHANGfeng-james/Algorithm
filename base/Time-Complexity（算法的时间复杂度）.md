> 我的整体行文和目标是：逐步推导出大O表示法，并以这个时间复杂度分析作为主题，后续会包含各种实际数据结构和算法的时间复杂度分析的案例。

数据结构和算法**本身解决**的是**“快"和"省"的问题**，即**如何让代码运行得更快，如何让代码更省存储空间**。所以，**执行效率是算法一个非常重要的考量指标**。那如何来衡量你编写的算法代码的执行效率呢？我们在评估（衡量）算法的执行效率时，一般考虑的就是时间和内存占用情况。

> 在对实际业务问题建模时，一般我们都在获取结果时，笼统地认为就是算法的执行效率。但在这个语境中，实际上就包括了数据结构的使用。“数据结构和算法，是不可分开讨论的，是相辅相成的关系！”

# 1 时间复杂度表示法

本篇的主题就是算法的时间复杂度分析，也就是分析算法执行效率与数据规模增长的变化趋势。而我们真正**需要的是一个不用具体的测试数据来测试，就可以粗略地估计算法的执行效率和内存占用的方法**。

来看一段下述代码：

~~~go
func cal(n int) int {
	var sum = 0
	i, j := 1, 1
	for i = 1; i <= n; i++ {
		for j = 1; j <= n; j++ {
			sum = sum + i*j
		}
	}
	return sum
}
~~~

假设每行代码执行的时间都一样，为 `unitTime`。那么上述第 5 和 6 行的 for 循环的执行时间就是：`2n * unitTime`。因此，总的来看整个程序执行的时间是：
$$
T(n) = (2 * n^2 + n + 2) * unitTime
$$
尽管我们不知道 unit_time 的具体值，但是通过这两段代码执行时间的推导过程，我们可以得到一个非常重要的规律，那就是，**所有代码的执行时间 T(n) 与每行代码的执行次数n成正比**。我们可以**把这个规律总结成一个公式**。
$$
T(n) = O(f(n))
$$
T(n) 我们已经讲过了，它表示代码执行的时间；n 表示**数据规模**的大小；f(n)表示**每行代码执行的次数总和**。公式中的O，表示代码的执行时间 T(n) 与 f(n) 表达式**成正比的关系**。这就是大O时间复杂度表示法。大O时间复杂度实际上**并不具体表示代码真正的执行时间**，而是**表示代码执行时间随数据规模增长的变化趋势**，所以，也叫作**渐进时间复杂度**(asymptotic time complexity)，简称**时间复杂度**。

我们要记住的是：使用大O表示法抽象出的时间复杂度，更精确地说，我们需要知道的是该复杂度表示的**关于数据规模的增大对代码执行时间的趋势**。因此对，上述代码的时间复杂度，可以表示为：
$$
T(n) = O(n^2)
$$
上面 3 个公式的过度中，我们可以很清楚看到时间复杂度表示法的**演进和抽象过程**。

# 2 分析方法

在时间复杂度分析中，总结出了如下 3 个分析方法：

* 只关注循环执行次数**最多**的代码；
* **加法法则**：总复杂度等于量级最大的那段代码的复杂度；
* **乘法法则**：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积。

# 3 常见的时间复杂度

常见的时间复杂度量级并不多，**按数量级递增**依次是：

* O(1)
* O(logn)
* O(sqrt(n)) 平方根阶
* O(n)
* O(nlogn) 线性对数阶
* O(n^2^)
* O(n^3^)
* O(n^4^)
* O(2^n^) 指数阶
* O(n!) 阶乘阶

# 5 最好、最坏、平均和均摊时间复杂度

~~~go
func find(array []int, n, x int) int {
	pos := -1
	for i := 0; i < n; i++ {
		if array[i] == x {
			pos = i
			break
		}
	}
	return pos
}
~~~

正如上述代码描述的场景，要查找的变量 `x` 在数组中的位置，有 `n + 1` 种情况：在数组的 `0 ~ (n - 1)` 位置中和不在数组中。**每种情况遍历数组的次数都不同**。为了表示代码在**不同情况下**的不同时间复杂度，我们需要引入三个概念：**最好情况**时间复杂度、**最坏情况**时间复杂度和**平均情况**时间复杂度。

顾名思义：

* 最好时间复杂度就是，在最理想的情况下（比如查找算法是从首元素开始遍历，且首元素恰好就是 x），执行这段代码的时间复杂度；

* 最坏时间复杂度就是，在最糟糕的情况下（比如上述待查找的 x 不在 array 数组中），执行这段代码的时间复杂度；

* 平均时间复杂度就是，在所有不同种情况中，执行这段代码的平均时间复杂度。这种描述并不直观，比如：我们把每种情况下，查找需要遍历的元素个数累加起来，然后再除以 `(n + 1)`，就可以得到**需要遍历的元素个数的平均值**，即：
  $$
  T(n) = n*(n+3)/2(n+1)
  $$
  上面这种计算平均值的方式，潜在地认为每种情况出现的**概率是相同的**！那如果笼统地认为，要查找的变量 x，要么在数组里，要么不在数组里，这两种情况出现的概率是相同的，都是 1/2。加权平均得到的值是：
  $$
  T(n) = (3n + 1)/4
  $$

只有**同一块代码**在**不同的情况**下，时间复杂度有**量级的差距**，我们才会使用这三种复杂度表示法来区分。

而**均摊时间复杂度**，它对应的分析方法就是：**摊还分析**（或者叫**平摊分析**）。**平均复杂度只在某些特殊情况下才会用到**，而**均摊时间复杂度应用的场景比它更加特殊、更加有限**。

摊还分析特殊的场景：对一个数据结构进行一组连续操作中，**大部分情况**下时间复杂度都很**低**，只有**个别情况**下时间复杂度比较**高**，而且这些操作之间存在**前后连贯的时序关系**，这个时候，我们就可以将这一组操作放在一块儿分析，看是否能将较高时间复杂度那次操作的耗时，**平摊**到其他那些时间复杂度比较低的操作上。而且，在能够应用均摊时间复杂度分析的场合，**一般均摊时间复杂度就等于最好情况时间复杂度**。均摊时间复杂度就是一种特殊的平均时间复杂度。

为什么要引入不同的时间复杂度分析概念？同一段代码，在不同输入的情况下，复杂度量级有可能是不一样的。这种情况下，就不能使用之前的方式来度量了。

# 4 案例分析

## 4.1 和 Tree 相关操作的时间复杂度分析

二叉查找树的**形态各式各样**。对于同一组数据，我们可以构造出多种二叉查找树。它们的查找、插入、删除操作的执行效率都是不一样的。不管操作是插入、删除还是查找，时间复杂度其实都跟树的高度成正比，也就是 O(height)。

